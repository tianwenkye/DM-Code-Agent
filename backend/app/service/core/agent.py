"""ç”± LLM API é©±åŠ¨çš„ ReAct é£æ ¼æ™ºèƒ½ä½“ã€‚"""

from __future__ import annotations

import json
from dataclasses import dataclass
from typing import Any, Callable, Dict, List, Optional

from ..clients.base_client import BaseLLMClient
from ..tools.base import Tool
from ..prompts import build_code_agent_prompt
from ..memory.context_compressor import ContextCompressor
from .planner import TaskPlanner, PlanStep


@dataclass
class Step:
    """è¡¨ç¤ºæ™ºèƒ½ä½“çš„ä¸€ä¸ªæ¨ç†æ­¥éª¤ã€‚"""

    thought: str                 # æ™ºèƒ½ä½“çš„æ€è€ƒè¿‡ç¨‹
    action: str                  # è¦æ‰§è¡Œçš„åŠ¨ä½œ/å·¥å…·åç§°
    action_input: Any            # åŠ¨ä½œçš„è¾“å…¥å‚æ•°
    observation: str             # æ‰§è¡ŒåŠ¨ä½œåçš„è§‚å¯Ÿç»“æœ
    raw: str = ""                # åŸå§‹å“åº”å†…å®¹


class ReactAgent:  
    """
    ReAct Agent å®ç°äº†æ¨ç†(Reasoning)å’Œè¡ŒåŠ¨(Action)çš„å¾ªç¯æ¨¡å¼ï¼Œå…è®¸æ™ºèƒ½ä½“é€šè¿‡ä¸ç¯å¢ƒäº¤äº’æ¥è§£å†³é—®é¢˜ã€‚
    å®ƒç»“åˆäº†ä»»åŠ¡è§„åˆ’ã€ä¸Šä¸‹æ–‡å‹ç¼©ç­‰åŠŸèƒ½ï¼Œæä¾›äº†ä¸€ä¸ªå®Œæ•´çš„æ™ºèƒ½ä½“æ‰§è¡Œæ¡†æ¶ã€‚
    
    Attributes:
        client (BaseLLMClient): ç”¨äºä¸å¤§è¯­è¨€æ¨¡å‹é€šä¿¡çš„å®¢æˆ·ç«¯
        tools (Dict[str, Tool]): å¯ç”¨å·¥å…·çš„å­—å…¸æ˜ å°„ï¼Œé”®ä¸ºå·¥å…·åç§°
        tools_list (List[Tool]): å·¥å…·åˆ—è¡¨ï¼Œç”¨äºè§„åˆ’å™¨åˆå§‹åŒ–
        max_steps (int): æœ€å¤§æ‰§è¡Œæ­¥éª¤æ•°
        temperature (float): LLMç”Ÿæˆæ–‡æœ¬çš„æ¸©åº¦å‚æ•°
        system_prompt (str): ç³»ç»Ÿæç¤ºè¯
        step_callback (Optional[Callable[[int, Step], None]]): æ­¥éª¤æ‰§è¡Œå›è°ƒå‡½æ•°
        enable_planning (bool): æ˜¯å¦å¯ç”¨ä»»åŠ¡è§„åˆ’åŠŸèƒ½
        enable_compression (bool): æ˜¯å¦å¯ç”¨ä¸Šä¸‹æ–‡å‹ç¼©åŠŸèƒ½
        conversation_history (List[Dict[str, str]]): å¯¹è¯å†å²è®°å½•
        planner (Optional[TaskPlanner]): ä»»åŠ¡è§„åˆ’å™¨å®ä¾‹
        compressor (Optional[ContextCompressor]): ä¸Šä¸‹æ–‡å‹ç¼©å™¨å®ä¾‹
    """

    def __init__(
        self,
        client: BaseLLMClient,
        tools: List[Tool],
        *,
        max_steps: int = 200,
        temperature: float = 0.0,
        system_prompt: Optional[str] = None,
        step_callback: Optional[Callable[[int, Step], None]] = None,   # æ­¥éª¤å›è°ƒå‡½æ•°
        enable_planning: bool = True,      # æ˜¯å¦å¯ç”¨è§„åˆ’
        enable_compression: bool = True,   # æ˜¯å¦å¯ç”¨ä¸Šä¸‹æ–‡å‹ç¼©
        skill_manager: Optional[Any] = None,  # æŠ€èƒ½ç®¡ç†å™¨
    ) -> None:
        """
        åˆå§‹åŒ– ReactAgent å®ä¾‹
        
        Args:
            client (BaseLLMClient): LLMå®¢æˆ·ç«¯å®ä¾‹
            tools (List[Tool]): å¯ç”¨å·¥å…·åˆ—è¡¨
            max_steps (int, optional): æœ€å¤§æ‰§è¡Œæ­¥éª¤æ•°ï¼Œé»˜è®¤ä¸º200
            temperature (float, optional): LLMç”Ÿæˆæ–‡æœ¬çš„æ¸©åº¦å‚æ•°ï¼Œé»˜è®¤ä¸º0.0
            system_prompt (Optional[str], optional): ç³»ç»Ÿæç¤ºè¯ï¼Œé»˜è®¤ä¸ºNoneï¼Œå°†ä½¿ç”¨é»˜è®¤æ„å»ºçš„æç¤ºè¯
            step_callback (Optional[Callable[[int, Step], None]], optional): 
                æ­¥éª¤æ‰§è¡Œå›è°ƒå‡½æ•°ï¼Œå¯ç”¨äºå®æ—¶ç›‘æ§æ‰§è¡Œè¿‡ç¨‹ï¼Œé»˜è®¤ä¸ºNone
            enable_planning (bool, optional): æ˜¯å¦å¯ç”¨ä»»åŠ¡è§„åˆ’åŠŸèƒ½ï¼Œé»˜è®¤ä¸ºTrue
            enable_compression (bool, optional): æ˜¯å¦å¯ç”¨ä¸Šä¸‹æ–‡å‹ç¼©åŠŸèƒ½ï¼Œé»˜è®¤ä¸ºTrue
            
        Raises:
            ValueError: å½“æä¾›çš„å·¥å…·åˆ—è¡¨ä¸ºç©ºæ—¶æŠ›å‡ºå¼‚å¸¸
            
        Examples:
            >>> from dm_agent.clients import OpenAIClient
            >>> from dm_agent.tools import default_tools
            >>> 
            >>> client = OpenAIClient(api_key="your-api-key")
            >>> tools = default_tools()
            >>> agent = ReactAgent(client, tools, max_steps=50)
            >>> result = agent.run("åˆ†æé¡¹ç›®ä»£ç ç»“æ„")
        """
        if not tools:
            raise ValueError("å¿…é¡»ä¸º ReactAgent æä¾›è‡³å°‘ä¸€ä¸ªå·¥å…·ã€‚")
        self.client = client

        # æˆ‘æ„Ÿè§‰è¿™é‡Œè¦æ”¹,èƒ½å¦è®¾ä¸€ä¸ªtools_mapping?
        
        self.tools = {tool.name: tool for tool in tools}
        self.tools_list = tools  # ä¿ç•™å·¥å…·åˆ—è¡¨ç”¨äºè§„åˆ’å™¨
        self.max_steps = max_steps
        self.temperature = temperature
        self.system_prompt = system_prompt or build_code_agent_prompt(tools)
        self.step_callback = step_callback
        # å¤šè½®å¯¹è¯å†å²è®°å½•
        self.conversation_history: List[Dict[str, str]] = []

        # è§„åˆ’å™¨
        self.enable_planning = enable_planning
        self.planner = TaskPlanner(client, tools) if enable_planning else None

        # ä¸Šä¸‹æ–‡å‹ç¼©å™¨ï¼ˆæ¯ 5 è½®å¯¹è¯å‹ç¼©ä¸€æ¬¡ï¼‰
        self.enable_compression = enable_compression
        self.compressor = ContextCompressor(client, compress_every=5, keep_recent=3) if enable_compression else None

        # æŠ€èƒ½ç®¡ç†å™¨
        self.skill_manager = skill_manager
        self._base_system_prompt = self.system_prompt
        self._base_tools = dict(self.tools)

    def run(self, task: str, *, max_steps: Optional[int] = None) -> Dict[str, Any]:
        """
        æ‰§è¡ŒæŒ‡å®šä»»åŠ¡
        
        è¯¥æ–¹æ³•å®ç°äº†å®Œæ•´çš„ReActå¾ªç¯ï¼ŒåŒ…æ‹¬ä»»åŠ¡è§„åˆ’ã€æ¨ç†ã€è¡ŒåŠ¨å’Œè§‚å¯Ÿç­‰é˜¶æ®µã€‚å®ƒæ”¯æŒä¸Šä¸‹æ–‡å‹ç¼©ä»¥
        æ§åˆ¶tokenæ¶ˆè€—ï¼Œå¹¶æä¾›å›è°ƒæœºåˆ¶ç”¨äºç›‘æ§æ‰§è¡Œè¿‡ç¨‹ã€‚
        
        Args:
            task (str): è¦æ‰§è¡Œçš„ä»»åŠ¡æè¿°
            max_steps (Optional[int], optional): è¦†ç›–é»˜è®¤çš„æœ€å¤§æ­¥éª¤æ•°
            
        Returns:
            result (Dict[str, Any]): åŒ…å«æœ€ç»ˆç­”æ¡ˆå’Œæ‰§è¡Œæ­¥éª¤çš„å­—å…¸
                    - final_answer (str): ä»»åŠ¡æ‰§è¡Œçš„æœ€ç»ˆç»“æœ
                    - steps (List[Dict]): æ‰§è¡Œçš„æ‰€æœ‰æ­¥éª¤ä¿¡æ¯åˆ—è¡¨
                
        Raises:
            ValueError: å½“ä»»åŠ¡ä¸æ˜¯éç©ºå­—ç¬¦ä¸²æ—¶æŠ›å‡ºå¼‚å¸¸
            
        Examples:
            >>> result = agent.run("å¸®æˆ‘åˆ†æé¡¹ç›®çš„ä»£ç ç»“æ„")
            >>> print(result["final_answer"])
            'å·²æˆåŠŸåˆ†æé¡¹ç›®ä»£ç ç»“æ„...'
        """
        if not isinstance(task, str) or not task.strip():
            raise ValueError("ä»»åŠ¡å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²ã€‚")

        steps: List[Step] = []
        limit = max_steps or self.max_steps # è·å–æœ€å¤§æ­¥éª¤æ•°

        # æŠ€èƒ½è‡ªåŠ¨é€‰æ‹©
        if self.skill_manager:
            self._apply_skills_for_task(task)

        # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆè®¡åˆ’ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        plan : List[PlanStep] = []
        if self.enable_planning and self.planner:
            try:
                plan = self.planner.plan(task)
                if plan:
                    plan_text = self.planner.get_progress()
                    print(f"\nğŸ“‹ ç”Ÿæˆçš„æ‰§è¡Œè®¡åˆ’ï¼š\n{plan_text}")
            except Exception as e:
                print(f"âš ï¸ è®¡åˆ’ç”Ÿæˆå¤±è´¥ï¼š{e}ï¼Œå°†ä½¿ç”¨å¸¸è§„æ¨¡å¼æ‰§è¡Œ")

        # æ·»åŠ æ–°ä»»åŠ¡åˆ°å¯¹è¯å†å²
        task_prompt : str = self._build_user_prompt(task, steps, plan)
        self.conversation_history.append({"role": "user", "content": task_prompt})

        for step_num in range(1, limit + 1):
            # ç¬¬äºŒæ­¥ï¼šå‹ç¼©ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
            messages_to_send = [{"role": "system", "content": self.system_prompt}] + self.conversation_history

            if self.enable_compression and self.compressor:
                if self.compressor.should_compress(self.conversation_history):
                    print(f"\nğŸ—œï¸ å‹ç¼©å¯¹è¯å†å²ä»¥èŠ‚çœ token...")
                    compressed_history = self.compressor.compress(self.conversation_history)
                    messages_to_send = [{"role": "system", "content": self.system_prompt}] + compressed_history

                    # æ˜¾ç¤ºå‹ç¼©ç»Ÿè®¡
                    stats = self.compressor.get_compression_stats(
                        self.conversation_history, compressed_history
                    )
                    print(
                        f"   å‹ç¼©ç‡ï¼š{stats['compression_ratio']:.1%}ï¼Œ"
                        f"èŠ‚çœ {stats['saved_messages']} æ¡æ¶ˆæ¯"
                    )

            # è·å– AI å“åº”
            raw = self.client.respond(messages_to_send, temperature=self.temperature)

            # å°† AI å“åº”æ·»åŠ åˆ°å†å²è®°å½•
            self.conversation_history.append({"role": "assistant", "content": raw})
            try:
                parsed = self._parse_agent_response(raw)
            except ValueError as exc:
                observation = f"è§£ææ™ºèƒ½ä½“å“åº”å¤±è´¥ï¼š{exc}"
                step = Step(
                    thought="",
                    action="error",
                    action_input={},
                    observation=observation,
                    raw=raw,
                )
                steps.append(step)

                # å°†é”™è¯¯è§‚å¯Ÿæ·»åŠ åˆ°å†å²è®°å½•
                self.conversation_history.append({"role": "user", "content": f"è§‚å¯Ÿï¼š{observation}"})

                if self.step_callback:
                    self.step_callback(step_num, step)
                continue
            
            # è·å–åŠ¨ä½œã€thought å’Œè¾“å…¥
            action = parsed.get("action", "").strip()
            thought = parsed.get("thought", "").strip()
            action_input = parsed.get("action_input")
            
            # æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if action == "finish":
                final = self._format_final_answer(action_input)
                step = Step(
                    thought=thought,
                    action=action,
                    action_input=action_input,
                    observation="<finished>",
                    raw=raw,
                )
                steps.append(step)

                # æ·»åŠ å®Œæˆæ ‡è®°åˆ°å†å²è®°å½•
                self.conversation_history.append({"role": "user", "content": f"ä»»åŠ¡å®Œæˆï¼š{final}"})

                if self.step_callback:
                    self.step_callback(step_num, step)
                return {"final_answer": final, "steps": [step.__dict__ for step in steps]}
            
            # æ£€æŸ¥å·¥å…·
            tool = self.tools.get(action)
            if tool is None:
                observation = f"æœªçŸ¥å·¥å…· '{action}'ã€‚"
                step = Step(
                    thought=thought,
                    action=action,
                    action_input=action_input,
                    observation=observation,
                    raw=raw,
                )
                steps.append(step)

                # å°†è§‚å¯Ÿç»“æœæ·»åŠ åˆ°å†å²è®°å½•
                self.conversation_history.append({"role": "user", "content": f"è§‚å¯Ÿï¼š{observation}"})

                if self.step_callback:
                    self.step_callback(step_num, step)
                continue

            # task_complete å·¥å…·å¯ä»¥æ¥å—å­—ç¬¦ä¸²æˆ–ç©ºå‚æ•°
            if action == "task_complete":
                if action_input is None:
                    action_input = {}
                elif isinstance(action_input, str):
                    action_input = {"message": action_input}
                elif not isinstance(action_input, dict):
                    action_input = {}
                try:
                    observation = tool.execute(action_input)
                except Exception as exc:  # noqa: BLE001 - å°†å·¥å…·é”™è¯¯ä¼ é€’ç»™ LLM
                    observation = f"å·¥å…·æ‰§è¡Œå¤±è´¥ï¼š{exc}"
            elif action_input is None:
                observation = "å·¥å…·å‚æ•°ç¼ºå¤±ï¼ˆaction_input ä¸º nullï¼‰ã€‚"
            elif not isinstance(action_input, dict):
                observation = "å·¥å…·å‚æ•°å¿…é¡»æ˜¯ JSON å¯¹è±¡ã€‚"
            else:
                try:
                    observation = tool.execute(action_input)
                except Exception as exc:  # noqa: BLE001 - å°†å·¥å…·é”™è¯¯ä¼ é€’ç»™ LLM
                    observation = f"å·¥å…·æ‰§è¡Œå¤±è´¥ï¼š{exc}"

            step = Step(
                thought=thought,
                action=action,
                action_input=action_input,
                observation=observation,
                raw=raw,
            )
            steps.append(step)

            # æ›´æ–°è®¡åˆ’è¿›åº¦ï¼ˆå¦‚æœæœ‰è®¡åˆ’ï¼‰
            if plan and self.planner:
                # æŸ¥æ‰¾å½“å‰æ­¥éª¤å¯¹åº”çš„è®¡åˆ’æ­¥éª¤
                for plan_step in plan:
                    if plan_step.action == action and not plan_step.completed:
                        self.planner.mark_completed(plan_step.step_number, observation)
                        break

            # å°†å·¥å…·æ‰§è¡Œç»“æœæ·»åŠ åˆ°å†å²è®°å½•
            tool_info = f"æ‰§è¡Œå·¥å…· {action}ï¼Œè¾“å…¥ï¼š{json.dumps(action_input, ensure_ascii=False)}\nè§‚å¯Ÿï¼š{observation}"
            self.conversation_history.append({"role": "user", "content": tool_info})

            # è°ƒç”¨å›è°ƒå‡½æ•°å®æ—¶è¾“å‡ºæ­¥éª¤
            if self.step_callback:
                self.step_callback(step_num, step)

            # æ£€æŸ¥æ˜¯å¦è°ƒç”¨äº† task_complete å·¥å…·
            if action == "task_complete" and not observation.startswith("å·¥å…·æ‰§è¡Œå¤±è´¥"):
                return {
                    "final_answer": observation,
                    "steps": [step.__dict__ for step in steps],
                }

        return {
            "final_answer": "è¾¾åˆ°æ­¥éª¤é™åˆ¶ä½†æœªå®Œæˆã€‚",
            "steps": [step.__dict__ for step in steps],
        }

    def _apply_skills_for_task(self, task: str) -> None:
        """æ ¹æ®ä»»åŠ¡è‡ªåŠ¨é€‰æ‹©å¹¶æ¿€æ´»ç›¸å…³æŠ€èƒ½ã€‚"""
        # æ¢å¤åŸºç¡€çŠ¶æ€ï¼Œé¿å…ä¸Šä¸€æ¬¡ä»»åŠ¡çš„æŠ€èƒ½æ®‹ç•™
        self.system_prompt = self._base_system_prompt
        self.tools = dict(self._base_tools)

        # è‡ªåŠ¨é€‰æ‹©
        selected = self.skill_manager.select_skills_for_task(task)
        if not selected:
            self.skill_manager.deactivate_all()
            return

        # æ¿€æ´»é€‰ä¸­æŠ€èƒ½
        self.skill_manager.activate_skills(selected)

        # è¿½åŠ æŠ€èƒ½ prompt
        prompt_addition = self.skill_manager.get_active_prompt_additions()
        if prompt_addition:
            self.system_prompt += prompt_addition

        # åˆå¹¶æŠ€èƒ½å·¥å…·
        skill_tools = self.skill_manager.get_active_tools()
        for tool in skill_tools:
            self.tools[tool.name] = tool

        # æ‰“å°æ¿€æ´»ä¿¡æ¯
        display_names = []
        for name in selected:
            skill = self.skill_manager.skills.get(name)
            if skill:
                display_names.append(skill.get_metadata().display_name)
        if display_names:
            print(f"\nğŸ¯ å·²æ¿€æ´»æŠ€èƒ½ï¼š{', '.join(display_names)}")

    def _build_user_prompt(self, task: str, steps: List[Step], plan: List[PlanStep] = None) -> str:
        """
        æ„å»ºç”¨æˆ·æç¤ºè¯
        
        Args:
            task (str): å½“å‰ä»»åŠ¡æè¿°
            steps (List[Step]): å·²æ‰§è¡Œçš„æ­¥éª¤åˆ—è¡¨
            plan (List[PlanStep], optional): æ‰§è¡Œè®¡åˆ’
            
        Returns:
            prompt (str): æ„å»ºå¥½çš„ç”¨æˆ·æç¤ºè¯å­—ç¬¦ä¸²
        """
        lines : List[str] = [f"ä»»åŠ¡ï¼š{task.strip()}"]

        # å¦‚æœæœ‰è®¡åˆ’ï¼Œæ·»åŠ åˆ°æç¤ºä¸­
        if plan:
            lines.append("\næ‰§è¡Œè®¡åˆ’ï¼š")
            for plan_step in plan:
                status = "âœ“" if plan_step.completed else "â—‹"
                lines.append(f"{status} æ­¥éª¤ {plan_step.step_number}: {plan_step.action} - {plan_step.reason}")

        if steps:
            lines.append("\nä¹‹å‰çš„æ­¥éª¤ï¼š")
            for index, step in enumerate(steps, start=1):
                lines.append(f"æ­¥éª¤ {index} æ€è€ƒï¼š{step.thought}")
                lines.append(f"æ­¥éª¤ {index} åŠ¨ä½œï¼š{step.action}")
                lines.append(f"æ­¥éª¤ {index} è¾“å…¥ï¼š{json.dumps(step.action_input, ensure_ascii=False)}")
                lines.append(f"æ­¥éª¤ {index} è§‚å¯Ÿï¼š{step.observation}")
        lines.append(
            "\nç”¨ JSON å¯¹è±¡å›åº”ï¼š{\"thought\": string, \"action\": string, \"action_input\": object|string}ã€‚"
        )
        return "\n".join(lines)

    def _parse_agent_response(self, raw: str) -> Dict[str, Any]:
        """
        è§£ææ™ºèƒ½ä½“å“åº”
        
        Args:
            raw (str): æ™ºèƒ½ä½“çš„åŸå§‹å“åº”å­—ç¬¦ä¸²
            
        Returns:
            parsed (Dict[str, Any]): è§£æåçš„JSONå¯¹è±¡
            
        Raises:
            ValueError: å½“å“åº”ä¸æ˜¯æœ‰æ•ˆçš„JSONæ—¶æŠ›å‡ºå¼‚å¸¸
        """
        candidate = raw.strip()
        if not candidate:
            raise ValueError("æ¨¡å‹è¿”å›ç©ºå“åº”ã€‚")
        try:
            parsed = json.loads(candidate)
        except json.JSONDecodeError:
            start = candidate.find("{")
            end = candidate.rfind("}")
            if start == -1 or end == -1 or end <= start:
                raise ValueError("å“åº”ä¸æ˜¯æœ‰æ•ˆçš„ JSONã€‚")
            snippet = candidate[start : end + 1]
            parsed = json.loads(snippet)
        if not isinstance(parsed, dict):
            raise ValueError("æ™ºèƒ½ä½“å“åº”çš„ JSON å¿…é¡»æ˜¯å¯¹è±¡ã€‚")
        return parsed

    def reset_conversation(self) -> None:
        """é‡ç½®å¯¹è¯å†å²
        
        æ¸…ç©ºæ‰€æœ‰å¯¹è¯å†å²è®°å½•ï¼Œä¸ºæ–°ä»»åŠ¡åšå‡†å¤‡ã€‚
        """
        self.conversation_history = []

    def get_conversation_history(self) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯å†å²
        
        Returns:
            conversation_history (List[Dict[str, str]]): å¯¹è¯å†å²è®°å½•çš„å‰¯æœ¬
        """
        return self.conversation_history.copy()

    @staticmethod
    def _format_final_answer(action_input: Any) -> str:
        """
        æ ¼å¼åŒ–æœ€ç»ˆç­”æ¡ˆ
        
        Args:
            action_input (Any): finishåŠ¨ä½œçš„è¾“å…¥å‚æ•°
            
        Returns:
            answer (str): æ ¼å¼åŒ–åçš„æœ€ç»ˆç­”æ¡ˆå­—ç¬¦ä¸²
        """
        if isinstance(action_input, str):
            return action_input
        if isinstance(action_input, dict) and "answer" in action_input:
            value = action_input["answer"]
            if isinstance(value, str):
                return value
        return json.dumps(action_input, ensure_ascii=False)
