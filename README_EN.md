# Your First AI Agent Project

<div align="center">

**Intelligent Code Agent Based on Multiple LLM APIs**

[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

[ä¸­æ–‡](README.md) | **English**

</div>

## ğŸ“– Project Overview

If you're just starting to learn about AI Agents and don't know where to begin, start with this project to learn or develop your own Agent applications.

This project provides all new AI Agent developers with an extremely low learning curve yet powerful **Code Agent**, based on the ReAct (Reasoning + Acting) architecture, supporting multiple large language models (DeepSeek, OpenAI, Claude, Gemini) for reasoning, and focused on software development and code-related tasks. The agent can:

### ğŸ¯ Core Capabilities â­ v1.2.0 New
- ğŸ“‹ **Task Planning** - Generate structured plans before execution, reduce ineffective operations by 30-50% (v1.1.0)
- ğŸ§  **Code Analysis** - Parse AST, extract function signatures, analyze dependencies (v1.1.0)
- ğŸ—œï¸ **Context Compression** - Auto-compress conversation history, support long conversations without token overflow (v1.1.0)
- ğŸ”Œ **MCP Protocol Support** - Integrate any MCP tools, unlimited extensibility (v1.2.0)
- ğŸ¯ **Skill Expert System** - Auto-activate domain expert capabilities based on task, inject specialized prompts and tools (v1.4.0) â­ New

### ğŸ› ï¸ Tool Capabilities
- ğŸ“ **Code Editing** - Precisely edit specific file lines with insert/replace/delete
- ğŸ” **Code Search** - Regex search with context display
- ğŸ§ª **Test Execution** - Run pytest/unittest test suites
- âœ¨ **Code Linting** - Run pylint/flake8/mypy/black linting tools
- ğŸ“ **File Operations** - Create, read (with line ranges), list files and directories (with recursive filtering)
- ğŸ **Python Execution** - Run Python code and scripts
- ğŸ’» **Shell Commands** - Execute system commands
- ğŸ¯ **Task Completion** - Intelligently mark task completion status
- ğŸ¨ **Interactive Interface** - User-friendly menu-based operation experience

## âœ¨ Key Features

### ğŸ¯ v1.1.0 New Core Features
#### ğŸ“‹ Task Planner
- **Smart Plan Generation** - Auto-generate 3-8 step structured plans before task execution
- **Real-time Progress Tracking** - Mark completed steps with clear execution progress display
- **30-50% Efficiency Boost** - Reduce ineffective tool calls and improve task success rate
- **Auto Fallback** - Automatically switch to regular mode if plan generation fails

#### ğŸ§  Code Analysis Tools
- **parse_ast** - Parse Python file AST, extract functions, classes, imports structure
- **get_function_signature** - Get complete function signature with type annotations
- **find_dependencies** - Analyze file dependencies (stdlib, third-party, local modules)
- **get_code_metrics** - Count code lines, functions, classes metrics

#### ğŸ—œï¸ Context Compressor
- **Auto Compression** - Auto-compress history every 5 turns, keep recent 3 turns intact
- **Smart Summary** - Extract key info (file paths, tool calls, errors, completed tasks)
- **Save Tokens** - Reduce 20-30% token consumption, support longer conversations
- **Seamless Integration** - Fully automatic, no manual intervention needed

#### ğŸ”Œ MCP Protocol Integration (Model Context Protocol) â­ v1.2.0 New
- **Zero-Code Extension** - Integrate any MCP tools via config file, no code changes needed
- **Pre-installed Playwright** - Built-in browser automation (navigate, screenshot, click, fill forms)
- **Pre-installed Context7** - Intelligent context management and semantic search
- **Unified Tool Interface** - MCP tools auto-wrapped as standard Tool objects
- **Lifecycle Management** - Auto-start and stop MCP server processes
- **Common MCP Support** - Playwright, Context7, Filesystem, SQLite, etc.
- **Detailed Documentation** - See [MCP_GUIDE.md](MCP_GUIDE.md) for complete integration guide

#### ğŸ¯ Skill Expert System â­ v1.4.0 New
- **Auto-Activation** - Automatically select and activate relevant domain expert skills based on task description
- **3 Built-in Experts** - Python Expert, Database Expert, Frontend Dev Expert, ready out of the box
- **Specialized Tool Injection** - Each skill can carry specialized tools (e.g., `python_best_practices`, `sql_review`)
- **Prompt Enhancement** - Activated skills auto-inject domain best practices into the system prompt
- **Custom Skills** - Support JSON config files for quick custom skill creation, no code needed
- **Python Class Extension** - For complex scenarios, define skills as Python classes with custom tools
- **Detailed Documentation** - See [SKILL_GUIDE.md](SKILL_GUIDE.md) for complete guide

### ğŸ¤– Multi-Model Support
- **DeepSeek** - Default model, cost-effective
- **OpenAI** - GPT-3.5/GPT-4 series models
- **Claude** - Anthropic Claude 3.5 series
- **Gemini** - Google Gemini series
- Support for custom Base URL and model parameters

### ğŸš€ Interactive CLI Interface
- **Friendly Menu System** - No need to memorize complex commands
- **Real-time Configuration** - Dynamically adjust runtime parameters
- **Colorful Output** - Clear and beautiful interface (supports colorama)
- **Tool List Viewer** - View all available tools with one click

### ğŸ› ï¸ Powerful Code Agent Toolset

**MCP Tools** â­ v1.2.0 New
- `mcp_playwright_*` - Browser automation tools (navigate, screenshot, click, forms)
- `mcp_context7_*` - Intelligent context management tools (store, retrieve, search)
- Support dynamic loading of any MCP tools

**Code Analysis Tools** (v1.1.0)
- `parse_ast` - Parse Python file AST structure
- `get_function_signature` - Extract function signature and types
- `find_dependencies` - Analyze file dependencies
- `get_code_metrics` - Get code metrics

**Code Editing Tools**
- `edit_file` - Precisely edit specific file lines (insert/replace/delete)
- `search_in_file` - Regex search with context display

**Testing and Linting Tools**
- `run_tests` - Run pytest/unittest test suites
- `run_linter` - Run pylint/flake8/mypy/black code linters

**File Operation Tools**
- `list_directory` - List directory contents (with recursive and type filtering)
- `read_file` - Read text files (with line number ranges)
- `create_file` - Create or overwrite files

**Code Execution Tools**
- `run_python` - Execute Python code
- `run_shell` - Execute Shell commands
- `task_complete` - Mark task as complete

### ğŸ¯ Flexible Usage
- **Interactive Mode** - Menu-based operation, suitable for continuous tasks
- **Multi-turn Conversation Mode** - Continuous dialogue with complete history â­ New
- **Command-line Mode** - Quick execution of single tasks
- **Batch Mode** - Support for script automation
- **Persistent Configuration** - Custom settings saved permanently â­ New

## ğŸ“‹ Prerequisites

- **Python 3.7+** (Recommended 3.9 or higher)
- **LLM API Key** - Choose based on model:
  - [DeepSeek API Key](https://platform.deepseek.com/) (default)
  - [OpenAI API Key](https://platform.openai.com/)
  - [Claude API Key](https://console.anthropic.com/)
  - [Gemini API Key](https://makersuite.google.com/app/apikey)

## ğŸ”§ Installation

### 1. Clone the Repository

```bash
git clone <repository-url>
cd dm-agent
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

**Dependencies**:
- `requests` - HTTP request library for calling LLM API
- `python-dotenv` - Environment variable management
- `colorama` - Colorful terminal output (optional but recommended)
- `google-generativeai` - Google Gemini official SDK

### 3. Configure API Key

Copy the `.env.example` file and rename it to `.env`, then add your real API key:

```bash
# Copy the example file
cp .env.example .env

# Edit the .env file, configure the corresponding key based on the model you're using
# DeepSeek (default)
DEEPSEEK_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxx

# OpenAI (optional)
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxx

# Claude (optional)
CLAUDE_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxxxxx

# Gemini (optional)
GEMINI_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxx
```

**âš ï¸ Security Notice**:
- The `.env` file contains your private API key and is configured in `.gitignore` to prevent it from being committed to Git
- Do not share the `.env` file with others or upload it to public repositories
- Only the `.env.example` file will be committed to the repository as a configuration template

Or set the environment variable in the command line:

**Windows (PowerShell)**:
```powershell
$env:DEEPSEEK_API_KEY="your_api_key_here"
```

**Linux/macOS**:
```bash
export DEEPSEEK_API_KEY="your_api_key_here"
```

## ğŸš€ Quick Start

### ğŸŒ Web UI Mode (Recommended) â­ v1.3.0+

The modern web interface delivers real-time conversations, visual settings, and tool management.

#### Install frontend dependencies (first time only)

```bash
# enter the frontend folder
cd frontend

# requires Node.js 16+
npm install
```

#### Launch the system

**1. Start the backend (project root):**
```bash
python app.py
```

**2. Start the frontend (new terminal, `frontend/` directory):**
```bash
cd frontend
npm run dev
```

**3. Open the interface:**
Visit **http://localhost:3000** in your browser.


#### ğŸ–¥ï¸ UI Highlights (actively refined)
- **Wide two-column layout** â€“ scales up to 1920px+ so prompts/plans live on the left and live status/logs on the right.
- **Scroll-inside cards** â€“ execution plan, status, and logs keep fixed heights and scroll internally, keeping the page calm even for long tasks.
- **Collapsible long replies** â€“ messages longer than ~600 characters or 12 lines collapse automatically; click â€œExpand all / Collapseâ€ to toggle readability.
- **Gradients & breathing cues** â€“ subtle gradients and animated status pills make it easy to spot the agentâ€™s progress at a glance.

---

### Interactive Mode (Recommended)

Run the program directly to enter the friendly menu interface:

```bash
python main.py
```

You will see:

```
======================================================================
              DM-Agent System
======================================================================
Welcome to the Multi-Model ReAct Agent System!

Main Menu:
  1. Execute New Task
  2. Multi-turn Conversation Mode
  3. View Available Tools
  4. Configuration Settings
  5. View Available Skills
  6. Exit Program

Please select an option (1-6):
```

### Command-line Mode (Quick Execution)

Execute tasks directly from the command line:

```bash
# Basic usage (using default DeepSeek)
python main.py "Create a hello.py file that prints hello world"

# Use OpenAI
python main.py "Your task" --provider openai --model gpt-4

# Use Claude
python main.py "Your task" --provider claude --model claude-3-5-sonnet-20241022

# Use Gemini
python main.py "Your task" --provider gemini --model gemini-1.5-flash

# Show detailed steps
python main.py "Calculate 123 + 456" --show-steps

# Custom configuration
python main.py "Your task" --max-steps 50 --temperature 0.5
```

## ğŸ“š Usage Examples

#### Task Planner Example
```bash
python main.py "Create a complete calculator program with add, subtract, multiply, divide functions and tests"
```

You will see:
```
ğŸ“‹ Generated Execution Plan:
Plan Progress: 0/5 steps completed

â—‹ Step 1: create_file - Create calculator main program file
â—‹ Step 2: edit_file - Add calculation functions
â—‹ Step 3: create_file - Create test file
â—‹ Step 4: run_tests - Run tests for verification
â—‹ Step 5: task_complete - Complete task
```

#### Code Analysis Tools Example
```bash
# Analyze file structure
python main.py "Analyze the code structure of main.py and list all functions and classes"

# Extract function signature
python main.py "Get the complete signature of the calculate function in calculator.py"

# Analyze dependencies
python main.py "Analyze what third-party libraries main.py depends on"

# Get code metrics
python main.py "Count the number of code lines in all Python files in the src directory"
```

#### Context Compression Example
In multi-turn conversation mode, auto-compress every 5 turns:
```
ğŸ—œï¸ Compressing conversation history to save tokens...
   Compression ratio: 62.5%, saved 10 messages
```

### Example 0.5: MCP Tools Usage â­ v1.2.0

#### Playwright MCP Example (Browser Automation)
```bash
# Open webpage and take screenshot
python main.py "Open https://www.example.com and save screenshot as example.png"

# Automate form filling
python main.py "Open https://example.com/login, enter 'testuser' in username field, 'password123' in password field, then click login"

# Extract webpage data
python main.py "Visit https://news.ycombinator.com and extract the top 10 news headlines"
```

#### Context7 MCP Example (Context Management)
```bash
# Store context
python main.py "Store the current project architecture information in Context7"

# Semantic search
python main.py "Search for database-related contexts in Context7"

# Related context
python main.py "Get historical contexts related to the current task"
```

#### Integrate New MCP Tools
Only 3 steps, no code needed:
1. Edit `mcp_config.json` to add configuration
2. Restart the system
3. Tools automatically available

See: [MCP_GUIDE.md](MCP_GUIDE.md)

### Example 0.6: Skill Expert System â­ v1.4.0

The agent automatically activates relevant skills based on the task, no manual configuration needed:

```bash
# Python Expert auto-activated
python main.py "Write a Python script to parse CSV files with type hints"
# ğŸ¯ Activated skills: Python Expert

# Database Expert + Python Expert auto-activated
python main.py "Optimize the SQL queries in my Django project"
# ğŸ¯ Activated skills: Python Expert, Database Expert

# Frontend Dev Expert auto-activated
python main.py "Create a React component to display a user list"
# ğŸ¯ Activated skills: Frontend Dev Expert
```

#### Create Custom Skills

Simply create a JSON file in the `dm_agent/skills/custom/` directory:

```json
{
  "name": "devops_expert",
  "display_name": "DevOps Expert",
  "description": "Docker, K8s, CI/CD best practices guidance",
  "keywords": ["docker", "kubernetes", "ci/cd", "deploy"],
  "prompt_addition": "You now have DevOps expert capabilities..."
}
```

See: [SKILL_GUIDE.md](SKILL_GUIDE.md)

### Example 1: Code Editing
```bash
# Insert code at a specific line
python main.py "Insert a print statement at line 10 in test.py"

# Replace code in a line range
python main.py "Replace lines 5-8 in main.py with a new function implementation"

# Search and modify code
python main.py "Search for all code containing 'TODO' in the project and list them"
```

### Example 2: Testing and Code Linting â­ New Feature
```bash
# Run tests
python main.py "Run all test cases in the tests directory"

# Code linting
python main.py "Check code quality in the src directory with flake8"

# Format checking
python main.py "Check if main.py conforms to black code style"
```

### Example 3: File Operations (Enhanced)
```bash
# Read specific line range
python main.py "Read lines 10-20 of config.py"

# Recursively list Python files
python main.py "List all .py files in the project"

# Create file
python main.py "Create a file named notes.txt with today's date"
```

### Example 4: Math Calculation

```bash
python main.py "Calculate the result of (100 + 200) * 3" --show-steps
```

### Example 5: Code Execution

```bash
python main.py "Use Python to generate 10 random numbers and save them to random.txt"
```

### Example 6: Complex Task

```bash
python main.py "Create a sort folder with 10 sorting algorithm implementations in both C++ and Python"
```

### Example 7: Multi-turn Conversation â­ New

```bash
python main.py
# Select option 2: Multi-turn Conversation Mode
# Conversation 1: "Create a test.py file"
# Conversation 2: "Write a function to print Hello in that file"
# Conversation 3: "Run that file"
# The agent will remember the context of test.py
```

## âš™ï¸ Command-line Arguments

```
python main.py [task] [options]

Positional Arguments:
  task                  Task description to execute (optional)

Optional Arguments:
  -h, --help           Show help message
  --api-key KEY        API key
  --provider PROVIDER  LLM provider (deepseek/openai/claude/gemini, default: deepseek) â­ New
  --model MODEL        Model name (default based on provider)
  --base-url URL       API base URL (optional, uses provider default) â­ New
  --max-steps N        Maximum steps (default: 100)
  --temperature T      Temperature 0.0-2.0 (default: 0.7)
  --show-steps         Show execution steps
  --interactive        Force interactive mode
```

**Note**: Default values can be permanently modified via `config.json`

## ğŸ¨ Interactive Menu Features

### 1ï¸âƒ£ Execute New Task
Enter a task description, and the agent will automatically execute and display results. Each execution is a fresh conversation.

### 2ï¸âƒ£ Multi-turn Conversation Mode â­ New
Enter continuous conversation mode where the agent remembers all conversation history and tool execution results:
- Type `exit` to quit conversation mode
- Type `reset` to clear conversation history
- The agent remembers file names, variables, and other context information

### 3ï¸âƒ£ View Tool List
View all available tools and their function descriptions.

### 4ï¸âƒ£ Configuration Settings â­ Enhanced
Dynamically adjust runtime parameters and optionally save permanently:
- **LLM Provider** (provider): deepseek/openai/claude/gemini â­ New
- **Model Name** (model): Choose based on provider
- **Base URL** (base_url): API base URL â­ New
- **Max Steps** (max_steps): 1-200 (default: 100)
- **Temperature** (temperature): 0.0-2.0 (default: 0.7)
- **Show Steps** (show_steps): Yes/No

After modification, you can choose to save to `config.json`, which will be automatically loaded on next startup.

### 5ï¸âƒ£ View Skills List â­ v1.4.0 New
View all available expert skills and their status:
- Display skill name, description, keywords, and specialized tool count
- Distinguish between built-in and custom skills
- Show current activation status

### 6ï¸âƒ£ Exit Program
Safely exit the application.

## âš™ï¸ Configuration Management

### Default Configuration
- **LLM Provider**: deepseek
- **Model**: deepseek-chat
- **Base URL**: https://api.deepseek.com
- **Max Steps**: 100
- **Temperature**: 0.7
- **Show Steps**: No

### Persistent Configuration
1. Start the program and select "Configuration Settings"
2. Modify parameters as prompted (including switching model providers)
3. Choose `y` to save as permanent configuration
4. Configuration is saved in the `config.json` file

Configuration file example (`config.json.example`):
```json
{
  "provider": "deepseek",
  "model": "deepseek-chat",
  "base_url": "https://api.deepseek.com",
  "max_steps": 100,
  "temperature": 0.7,
  "show_steps": false
}
```

**Note**:
- Gemini uses the official Google SDK and doesn't need `base_url` configuration
- Other providers can customize `base_url` as needed (e.g., using a proxy)

**Tip**: `config.json` is added to `.gitignore` and will not be committed to git

## ğŸ’¡ Tips and Tricks

1. **Continuous Tasks** - Use interactive mode to avoid repeatedly starting the program
2. **Debug Tasks** - Use `--show-steps` to view detailed execution process
3. **Experimental Tasks** - Increase temperature value for more creative results
4. **Complex Tasks** - Increase max-steps to allow more reasoning steps (default is 100)
5. **Quick Testing** - Command-line mode is suitable for scripts and automation


## ğŸ”„ Project Structure

```
dm-code-agent/
â”œâ”€â”€ main.py                         # Main program entry (Interactive CLI)
â”œâ”€â”€ check_mcp_env.py                # MCP environment check tool (v1.2.0)
â”œâ”€â”€ dm_agent/                       # Core agent package
â”‚   â”œâ”€â”€ __init__.py                # Package initialization and public API
â”‚   â”œâ”€â”€ core/                      # Core Agent implementation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ agent.py              # ReactAgent core logic
â”‚   â”‚   â””â”€â”€ planner.py            # Task planner (v1.1.0)
â”‚   â”œâ”€â”€ clients/                   # LLM clients
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_client.py        # Base client class
â”‚   â”‚   â”œâ”€â”€ deepseek_client.py    # DeepSeek client
â”‚   â”‚   â”œâ”€â”€ openai_client.py      # OpenAI client
â”‚   â”‚   â”œâ”€â”€ claude_client.py      # Claude client
â”‚   â”‚   â”œâ”€â”€ gemini_client.py      # Gemini client
â”‚   â”‚   â””â”€â”€ llm_factory.py        # Client factory
â”‚   â”œâ”€â”€ mcp/                       # MCP integration (v1.2.0)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ client.py             # MCP client
â”‚   â”‚   â”œâ”€â”€ config.py             # MCP configuration management
â”‚   â”‚   â””â”€â”€ manager.py            # MCP manager
â”‚   â”œâ”€â”€ skills/                    # Skill expert system (v1.4.0) â­ New
â”‚   â”‚   â”œâ”€â”€ __init__.py           # Module exports
â”‚   â”‚   â”œâ”€â”€ base.py               # Skill base class and metadata
â”‚   â”‚   â”œâ”€â”€ selector.py           # Skill auto-selector
â”‚   â”‚   â”œâ”€â”€ manager.py            # Skill manager
â”‚   â”‚   â”œâ”€â”€ builtin/              # Built-in skills
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ python_expert.py  # Python Expert
â”‚   â”‚   â”‚   â”œâ”€â”€ db_expert.py      # Database Expert
â”‚   â”‚   â”‚   â””â”€â”€ frontend_dev.py   # Frontend Dev Expert
â”‚   â”‚   â””â”€â”€ custom/               # Custom skills (JSON files)
â”‚   â”‚       â””â”€â”€ .gitkeep
â”‚   â”œâ”€â”€ memory/                    # Memory and context management (v1.1.0)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ context_compressor.py # Context compressor
â”‚   â”œâ”€â”€ tools/                     # Toolset
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py               # Tool base class
â”‚   â”‚   â”œâ”€â”€ file_tools.py         # File operation tools
â”‚   â”‚   â”œâ”€â”€ code_analysis_tools.py # Code analysis tools (v1.1.0)
â”‚   â”‚   â””â”€â”€ execution_tools.py    # Code execution tools
â”‚   â””â”€â”€ prompts/                   # Prompt management
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ system_prompts.py     # Prompt building functions
â”‚       â””â”€â”€ code_agent_prompt.md  # Prompt template
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ .env.example                   # Environment variable configuration template
â”œâ”€â”€ config.json.example            # Configuration file example
â”œâ”€â”€ mcp_config.json.example        # MCP configuration example (v1.2.0)
â”œâ”€â”€ .gitignore                     # Git ignore rules
â”œâ”€â”€ MCP_GUIDE.md                   # MCP integration guide (v1.2.0)
â”œâ”€â”€ SKILL_GUIDE.md                 # Skill system guide (v1.4.0) â­ New
â”œâ”€â”€ README.md                      # Chinese documentation
â””â”€â”€ README_EN.md                   # English documentation
```

## ğŸ¤ Contributing

Issues and Pull Requests are welcome!

## ğŸ“„ License

This project is licensed under the MIT License.

**Start Learning AI Agents!** ğŸš€
